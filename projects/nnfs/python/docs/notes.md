# Notes

## Activation Functions

1. **ReLu** is fast to calculate for non-linear regression
2. **Softmax** forces positive and normalizes to all values
  - Maximum exponent is 0 to keep values between 0 and 1
